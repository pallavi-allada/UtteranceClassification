{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers_BERT_Utterance_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a8ba603cd864d0e8cb2941ce5392c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ce7541cb6804f6eb5871216990bade8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c29a61e20cf748aa8b67bbeffbdddecb",
              "IPY_MODEL_eac2969fbffd4c6a9d1ef7ee8d35fb68"
            ]
          }
        },
        "6ce7541cb6804f6eb5871216990bade8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c29a61e20cf748aa8b67bbeffbdddecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0e38df96b214a18907d0ba7dc8a7640",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d52b4700bd34a4a8ba39ee01a4cb32e"
          }
        },
        "eac2969fbffd4c6a9d1ef7ee8d35fb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa13843d398147c7a778b20ca5fae66c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 104kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf81c16f6f574ead940afd01a597202e"
          }
        },
        "f0e38df96b214a18907d0ba7dc8a7640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d52b4700bd34a4a8ba39ee01a4cb32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa13843d398147c7a778b20ca5fae66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf81c16f6f574ead940afd01a597202e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1830daa108a4f548c7e92c40ae8362c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd7a78fdfbe7447e88cb8e3e228cd068",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c1a0790420540a7b0e3011f7adfb27e",
              "IPY_MODEL_d798137435964785b13e16786ef8a958"
            ]
          }
        },
        "bd7a78fdfbe7447e88cb8e3e228cd068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c1a0790420540a7b0e3011f7adfb27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_750b184c3685457faad3c3e938d2e188",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27375fcb80324d0ab2d00be133cdc1d7"
          }
        },
        "d798137435964785b13e16786ef8a958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e49dbfb47eb845ac9a912801d658957f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 31.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f432ab9b30c4516a589aa0237f64164"
          }
        },
        "750b184c3685457faad3c3e938d2e188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27375fcb80324d0ab2d00be133cdc1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e49dbfb47eb845ac9a912801d658957f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f432ab9b30c4516a589aa0237f64164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46d6f3d82c8c42dea8bb059e24625139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_90f31e2a21ec45feaa1738e35380cc6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_803cb0cceee048b58f2fe5578dbb509a",
              "IPY_MODEL_0c986c7f4f7c4bd0a6ff9cf8490a7931"
            ]
          }
        },
        "90f31e2a21ec45feaa1738e35380cc6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "803cb0cceee048b58f2fe5578dbb509a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec27235b3174520bb53beb34403cdc7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_074123e2a3654af89861aaec6ca00de7"
          }
        },
        "0c986c7f4f7c4bd0a6ff9cf8490a7931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69512a848d354f25b4b61c1485857552",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.99MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_633242348c604733b3ddc6c2b042403e"
          }
        },
        "1ec27235b3174520bb53beb34403cdc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "074123e2a3654af89861aaec6ca00de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69512a848d354f25b4b61c1485857552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "633242348c604733b3ddc6c2b042403e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavi-allada/UtteranceClassification/blob/main/src/Transformers_BERT_Utterance_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZabuYbCgfWic"
      },
      "source": [
        "Transformer based encodings to check if the context-aware embeddings provide better performance than the static embeddings of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB0yelGOIP3T",
        "outputId": "0aa60c60-a2e2-4acc-8ec8-6b72533ff109"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pGK2pkaGGRO",
        "outputId": "5a14bc64-d588-477d-afcd-cd26497c778c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 7.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA92o7aPIbu7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os as os\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy.data import Field, Dataset, BucketIterator, Iterator, Example\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39urBQLE35h"
      },
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer, BertModel,BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tfnYtyffbt5",
        "outputId": "51716366-af1e-41e6-c598-66d082ceb8dd"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Oh9lLwIqeK"
      },
      "source": [
        "ROOT_DIR = \"/content/drive/MyDrive/Colab Notebooks/Cognizer\"\n",
        "\n",
        "DATA_DIR = \"data\"\n",
        "MODEL_DIR = \"models\"\n",
        "\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV = \"test.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTBPGySlqrIO"
      },
      "source": [
        "Read train and test data from CSV files and make Examples for creating an Iterator - BucketIterator, to be able to batch the examples of same length together for processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rx6qVSCJAPu",
        "outputId": "4f214912-b54d-4d56-9e3d-8521d38c9475"
      },
      "source": [
        "train = pd.read_csv(os.path.join(ROOT_DIR,DATA_DIR,TRAIN_CSV))\n",
        "test = pd.read_csv(os.path.join(ROOT_DIR,DATA_DIR,TEST_CSV))\n",
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4137, 3), (460, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZg_D9cPMwMH"
      },
      "source": [
        "#convert tag to label\n",
        "def tag2label(tag):\n",
        "  return (0 if tag == \"Contract\" else (1 if tag == \"Email\" else (2 if tag == \"Calendar\" else (3 if tag == \"Contact\" else (4 if tag == \"Document\" else (5 if tag == \"Employee\" else 6))))))\n",
        "\n",
        "#convert label to tag\n",
        "def label2tag(lbl):\n",
        "  return (\"Contract\" if lbl == 0 else (\"Email\" if lbl == 1 else (\"Calendar\" if lbl == 2 else (\"Contact\" if lbl == 3 else (\"Document\" if lbl == 4 else (\"Employee\" if lbl == 5 else \"Keyword\"))))))\n",
        "\n",
        "train[\"label\"] = train[\"tags\"].apply(tag2label)\n",
        "test[\"label\"] = test[\"tags\"].apply(tag2label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THbKlFb0eols",
        "outputId": "a27ca245-8ae1-4e3a-b66c-018284e3d4e0"
      },
      "source": [
        "NUM_CLASSES = len(train[\"label\"].unique())\n",
        "NUM_CLASSES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8FPrkxBtI6h"
      },
      "source": [
        "Identifying the max sentence length in the given training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkfYXvlWrfnJ",
        "outputId": "c59bdb63-7c98-4fd7-d965-7bfcbd7e8ed4"
      },
      "source": [
        "train[\"length\"] = train[\"question\"].apply(lambda x: len(x.split()))\n",
        "max(train[\"length\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fxPQeMROcw"
      },
      "source": [
        "The longest sentence in the train set is 28 words, but we need to identify what is the max number of tokens that the BertTokenizer splits the sentences into. This will. be useful for padding later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVKZN9MLrAaM"
      },
      "source": [
        "We need to convert text to numbers, by following the requirements:\n",
        "\n",
        "1)Add special tokens to separate sentences and do classification\n",
        "\n",
        "2)Pass sequences of constant length (introduce padding)\n",
        "\n",
        "3)Create array of 0s (pad token) and 1s (real token) called attention mask\n",
        "\n",
        "The Transformers library provides a wide variety of Transformer models (including BERT. \n",
        "We can use a cased and uncased version of BERT and tokenizer. I've experimented with both. The cased version works better. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "9a8ba603cd864d0e8cb2941ce5392c4c",
            "6ce7541cb6804f6eb5871216990bade8",
            "c29a61e20cf748aa8b67bbeffbdddecb",
            "eac2969fbffd4c6a9d1ef7ee8d35fb68",
            "f0e38df96b214a18907d0ba7dc8a7640",
            "8d52b4700bd34a4a8ba39ee01a4cb32e",
            "fa13843d398147c7a778b20ca5fae66c",
            "bf81c16f6f574ead940afd01a597202e",
            "e1830daa108a4f548c7e92c40ae8362c",
            "bd7a78fdfbe7447e88cb8e3e228cd068",
            "9c1a0790420540a7b0e3011f7adfb27e",
            "d798137435964785b13e16786ef8a958",
            "750b184c3685457faad3c3e938d2e188",
            "27375fcb80324d0ab2d00be133cdc1d7",
            "e49dbfb47eb845ac9a912801d658957f",
            "3f432ab9b30c4516a589aa0237f64164",
            "46d6f3d82c8c42dea8bb059e24625139",
            "90f31e2a21ec45feaa1738e35380cc6a",
            "803cb0cceee048b58f2fe5578dbb509a",
            "0c986c7f4f7c4bd0a6ff9cf8490a7931",
            "1ec27235b3174520bb53beb34403cdc7",
            "074123e2a3654af89861aaec6ca00de7",
            "69512a848d354f25b4b61c1485857552",
            "633242348c604733b3ddc6c2b042403e"
          ]
        },
        "id": "BNZlJ_e6FaKo",
        "outputId": "824a5c68-0415-445a-d509-c12b559bbfe5"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a8ba603cd864d0e8cb2941ce5392c4c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1830daa108a4f548c7e92c40ae8362c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46d6f3d82c8c42dea8bb059e24625139",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei6kVt37MScf"
      },
      "source": [
        "Lets try to tokenise using an example and convert to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L15cd8aL83A",
        "outputId": "8685e75b-93f7-43d5-90c2-86f5a97f67f1"
      },
      "source": [
        "sample_ques = \"What are some services offered by Autodesk?\"\n",
        "tokens = tokenizer.tokenize(sample_ques)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_ques}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentence: What are some services offered by Autodesk?\n",
            "   Tokens: ['what', 'are', 'some', 'services', 'offered', 'by', 'auto', '##des', '##k', '?']\n",
            "Token IDs: [2054, 2024, 2070, 2578, 3253, 2011, 8285, 6155, 2243, 1029]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC29ZgzNMnuk"
      },
      "source": [
        "As mentioned in first requirement, we need to add special token to the converted sentence like\n",
        "\n",
        "[CLS] - we must add this token to the start of each sentence, so BERT knows we're doing classification.\n",
        "\n",
        "[SEP] - marker for ending of a sentence\n",
        "\n",
        "[PAD] - for padding\n",
        "\n",
        "[UNK] - for unknown tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ies4j6LvMxHk",
        "outputId": "e10617e6-6454-4365-c590-5f19ba0d3ced"
      },
      "source": [
        "print(tokenizer.cls_token, tokenizer.cls_token_id)\n",
        "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
        "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
        "print(tokenizer.unk_token, tokenizer.unk_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 101\n",
            "[SEP] 102\n",
            "[PAD] 0\n",
            "[UNK] 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZgRnxRWNfM9"
      },
      "source": [
        "This requirement can be accomplished by the encode_plus() method. The token_ids are stored in a tensor and padded to 30."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw9enjbtNepT"
      },
      "source": [
        "encoding = tokenizer.encode_plus(sample_ques,\n",
        "  max_length= 30, #MAX_LEN but for now padding to 30\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  # pad_to_max_length=True, #This is deprecated \n",
        "  padding='max_length',\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgDnQ9EnPp0b",
        "outputId": "f36e9a9b-3317-4de6-e664-b29046e1d743"
      },
      "source": [
        "print(encoding.keys() )\n",
        "print(len(encoding['input_ids'][0]))\n",
        "print(encoding['input_ids'][0], encoding['attention_mask'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "30\n",
            "tensor([ 101, 2054, 2024, 2070, 2578, 3253, 2011, 8285, 6155, 2243, 1029,  102,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLs5exvpP4IL"
      },
      "source": [
        "Cross checking the tokens from ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHFBYwR4QCUp",
        "outputId": "fe8d54d7-ec4a-4744-d712-658e2c48ce03"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'what',\n",
              " 'are',\n",
              " 'some',\n",
              " 'services',\n",
              " 'offered',\n",
              " 'by',\n",
              " 'auto',\n",
              " '##des',\n",
              " '##k',\n",
              " '?',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6plQBgG-R3ZK"
      },
      "source": [
        "Let's identify the max length of token of the questions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA2Y1Q-IR-zD",
        "outputId": "544e0c62-4dfe-4d7b-b9d3-e9080fa8e002"
      },
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in train.question:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))\n",
        "\n",
        "print(\"Maximum number of tokens:\",max(token_lens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum number of tokens: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_bDh6rISaTr"
      },
      "source": [
        "MAX_LEN = 50\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7GuJWDESnzb"
      },
      "source": [
        "class UtteranceDataset(Dataset):\n",
        "\n",
        "  def __init__(self, questions, labels, tokenizer, max_len):\n",
        "    self.questions = questions\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.questions)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    question = str(self.questions[item])\n",
        "    label = self.labels[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      question,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      # pad_to_max_length=True,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'questions': question,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'labels': torch.tensor(label, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlJtNNDJUxRW"
      },
      "source": [
        "#Helper function to create data loader\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = UtteranceDataset(\n",
        "    questions=df[\"question\"].to_numpy(),\n",
        "    labels=df[\"label\"].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(ds,batch_size=BATCH_SIZE,num_workers=NUM_WORKERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdX1yOosVYBZ"
      },
      "source": [
        "train_data_loader = create_data_loader(train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbAKFrzFYLyF"
      },
      "source": [
        "Let's take a look at an example data from loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0KgfXuRYMVm",
        "outputId": "d22756ba-f44c-4c31-f718-b9cd024cefc8"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "print(data.keys())\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['labels'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['questions', 'input_ids', 'attention_mask', 'labels'])\n",
            "torch.Size([16, 50])\n",
            "torch.Size([16, 50])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CC98MgAZN_W"
      },
      "source": [
        "Let's try to create a BertModel and try to pass the sample question to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ighHoV7fZGdo",
        "outputId": "0bfa1ddd-dbc5-42f3-e475-4ad8ec8883ce"
      },
      "source": [
        "bert_model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME,num_labels=NUM_CLASSES,output_attentions=False,output_hidden_states=False)\n",
        "                                                      \n",
        "bert_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v_2cdGCZbuz",
        "outputId": "44f9f396-2eab-447e-ca47-3c0c15e06d70"
      },
      "source": [
        "output = bert_model(input_ids=data['input_ids'].to(device), token_type_ids=None, attention_mask=data['attention_mask'].to(device), labels = data['labels'].to(device))\n",
        "print(output.loss, output.logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0375,  0.2770,  0.7672,  0.2584, -0.0080,  0.0137,  0.5587],\n",
            "        [-0.0332,  0.2947,  0.6791,  0.2202, -0.0179, -0.0071,  0.5931],\n",
            "        [-0.0109,  0.2691,  0.7307,  0.1975, -0.0335,  0.0448,  0.5731],\n",
            "        [-0.0696,  0.1742,  0.8161,  0.1917,  0.0286,  0.0543,  0.5483],\n",
            "        [-0.0504,  0.2092,  0.8087,  0.2331,  0.0118,  0.0056,  0.4869],\n",
            "        [-0.0533,  0.0277,  0.9455,  0.1666, -0.0800,  0.0288,  0.5003],\n",
            "        [-0.0497,  0.1646,  0.7926,  0.1420, -0.1282, -0.0130,  0.5324],\n",
            "        [-0.0849,  0.3590,  0.5642,  0.1264, -0.0111, -0.1068,  0.5344],\n",
            "        [-0.1246,  0.3165,  0.7448,  0.2394, -0.1365, -0.0532,  0.5919],\n",
            "        [-0.1010,  0.1717,  0.8785,  0.1816, -0.0680, -0.0100,  0.5033],\n",
            "        [-0.0657,  0.2547,  0.6975,  0.2650, -0.0165, -0.0011,  0.5914],\n",
            "        [-0.0502,  0.2193,  0.7126,  0.2253, -0.0362, -0.0042,  0.5804],\n",
            "        [ 0.0235,  0.1583,  0.9764,  0.2112, -0.1040,  0.0323,  0.4735],\n",
            "        [-0.0781,  0.4631,  0.5156,  0.1966,  0.0558, -0.0877,  0.5087],\n",
            "        [-0.1336,  0.2872,  0.7178,  0.2316,  0.0311, -0.0497,  0.6032],\n",
            "        [-0.2104,  0.2080,  0.6635,  0.1896,  0.0071, -0.1141,  0.3514]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O5EnGfRu8a6"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvGyqZGCqGGB"
      },
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME,num_labels=NUM_CLASSES,output_attentions=False,output_hidden_states=False)\n",
        "\n",
        "    def forward(self, text, attention_mask, label):\n",
        "        # print(\"text in forward:\", text)\n",
        "        # print(\"label in forward:\", label)\n",
        "        outputs = self.encoder(input_ids=text, token_type_ids=None, attention_mask=attention_mask,labels= label)\n",
        "        logits = outputs.logits\n",
        "        loss = outputs.loss\n",
        "        return loss, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YB6bp4K2CY6",
        "outputId": "fe792fff-df6a-4bf1-a6cf-3ec5024117d9"
      },
      "source": [
        "model_try = BERT().to(device)\n",
        "loss, logits = model_try(data['input_ids'].to(device), data['attention_mask'].to(device), None)\n",
        "\n",
        "print(loss, logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "None tensor([[ 0.7812,  0.1433, -0.2664, -0.0534, -0.2371, -0.0926,  0.5412],\n",
            "        [ 0.8640,  0.1794, -0.3105, -0.0218, -0.2613, -0.1156,  0.5269],\n",
            "        [ 0.7931,  0.1144, -0.2865, -0.0477, -0.1455, -0.1556,  0.5142],\n",
            "        [ 0.7758,  0.0779, -0.2991, -0.0733, -0.1138, -0.1520,  0.5411],\n",
            "        [ 0.6861,  0.0827, -0.2998, -0.0475, -0.2119, -0.1539,  0.5186],\n",
            "        [ 0.7149,  0.1098, -0.2774, -0.1108,  0.0208, -0.2806,  0.6893],\n",
            "        [ 0.6623,  0.2115, -0.2947,  0.0368, -0.1163, -0.2064,  0.5408],\n",
            "        [ 0.8902,  0.0971, -0.3084,  0.0749, -0.3486, -0.0113,  0.4177],\n",
            "        [ 0.8413,  0.1468, -0.3392,  0.0076, -0.2970, -0.1344,  0.4475],\n",
            "        [ 0.7448,  0.2213, -0.2508, -0.0473, -0.1384, -0.2108,  0.5625],\n",
            "        [ 0.8013,  0.1436, -0.3574, -0.0658, -0.2299, -0.1609,  0.5088],\n",
            "        [ 0.7386,  0.2198, -0.3416, -0.0484, -0.2353, -0.1076,  0.5117],\n",
            "        [ 0.6919,  0.1228, -0.3557, -0.0858, -0.0669, -0.2664,  0.5635],\n",
            "        [ 0.9811,  0.1023, -0.2911,  0.0596, -0.3734, -0.0499,  0.4248],\n",
            "        [ 0.8229,  0.1939, -0.3579, -0.0194, -0.2759, -0.1155,  0.5196],\n",
            "        [ 0.6923, -0.1012, -0.2086, -0.0406, -0.1445, -0.0125,  0.2733]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7atFoq3Pv3mZ"
      },
      "source": [
        "Methods to save and load best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8hnUtkJPGI_"
      },
      "source": [
        "# Save and Load Functions\n",
        "\n",
        "def save_checkpoint(save_path, model, valid_loss):    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    \n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "\n",
        "    return state_dict['valid_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dpFqKExPIkF"
      },
      "source": [
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_metrics(load_path):\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbFwk7KTPWww"
      },
      "source": [
        "EPOCHS = 5\n",
        "def train(model,optimizer,criterion = nn.CrossEntropyLoss(), eval_every = len(train_data_loader) // 2, best_valid_loss = float(\"Inf\")):\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    # training loop\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        for data in train_data_loader:\n",
        "            input_ids = data['input_ids'].to(device)\n",
        "            attention_mask = data['attention_mask'].to(device)\n",
        "            labels = data['labels'].to(device)\n",
        "            \n",
        "            loss,_ = model(input_ids, attention_mask, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update running values\n",
        "            running_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            # evaluation step\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():                    \n",
        "\n",
        "                    # validation loop\n",
        "                    for test_data in test_data_loader:\n",
        "                        test_input_ids = test_data['input_ids'].to(device)\n",
        "                        test_attention_mask = test_data['attention_mask'].to(device)\n",
        "                        test_labels = test_data['labels'].to(device)\n",
        "                        loss, _ = model(test_input_ids, test_attention_mask, test_labels)\n",
        "                        \n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                # evaluation\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(test_data_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                # resetting running values\n",
        "                running_loss = 0.0                \n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                #training progress\n",
        "                print('\\nEpoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, EPOCHS, global_step, EPOCHS*len(train_data_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "                \n",
        "                # checkpoint\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint(os.path.join(ROOT_DIR, MODEL_DIR,'model.pt'), model, best_valid_loss)\n",
        "                    save_metrics(os.path.join(ROOT_DIR, MODEL_DIR,'metrics.pt'), train_loss_list, valid_loss_list, global_steps_list)\n",
        "    \n",
        "    save_metrics(os.path.join(ROOT_DIR, MODEL_DIR,'metrics.pt'), train_loss_list, valid_loss_list, global_steps_list)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiVCQ79Vzqvh"
      },
      "source": [
        "Training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKqEvMmHznYf",
        "outputId": "ece2b581-d606-4069-bd47-62fc51cd1a7c"
      },
      "source": [
        "model = BERT().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "train(model=model, optimizer=optimizer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/5], Step [129/1295], Train Loss: 0.9850, Valid Loss: 0.4117\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/metrics.pt\n",
            "\n",
            "Epoch [1/5], Step [258/1295], Train Loss: 0.3507, Valid Loss: 0.2079\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/metrics.pt\n",
            "\n",
            "Epoch [2/5], Step [387/1295], Train Loss: 0.1615, Valid Loss: 0.1481\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/metrics.pt\n",
            "\n",
            "Epoch [2/5], Step [516/1295], Train Loss: 0.1411, Valid Loss: 0.1488\n",
            "\n",
            "Epoch [3/5], Step [645/1295], Train Loss: 0.0735, Valid Loss: 0.1345\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/metrics.pt\n",
            "\n",
            "Epoch [3/5], Step [774/1295], Train Loss: 0.0779, Valid Loss: 0.1558\n",
            "\n",
            "Epoch [4/5], Step [903/1295], Train Loss: 0.0440, Valid Loss: 0.1673\n",
            "\n",
            "Epoch [4/5], Step [1032/1295], Train Loss: 0.0483, Valid Loss: 0.1487\n",
            "\n",
            "Epoch [5/5], Step [1161/1295], Train Loss: 0.0378, Valid Loss: 0.1669\n",
            "\n",
            "Epoch [5/5], Step [1290/1295], Train Loss: 0.0290, Valid Loss: 0.1561\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Cognizer/models/metrics.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5o79tQoPfYj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "34c7d815-8354-4e14-b4cb-40be5b5f74b0"
      },
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics(os.path.join(ROOT_DIR, MODEL_DIR,'metrics.pt'))\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Cognizer/models/metrics.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub8jxw9-2i7Q"
      },
      "source": [
        "As data is less, using the data from test.csv that was used for validation during training to also create a classifiation report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MbtXBaRPfWD"
      },
      "source": [
        "# Evaluation Function\n",
        "\n",
        "def evaluate(model):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for test_data in test_data_loader:\n",
        "            test_input_ids = test_data['input_ids'].to(device)\n",
        "            test_attention_mask = test_data['attention_mask'].to(device)\n",
        "            test_labels = test_data['labels'].to(device)\n",
        "            _, logits = model(test_input_ids, test_attention_mask, None)\n",
        "\n",
        "            y_pred.extend(torch.argmax(logits, 1).tolist())\n",
        "            y_true.extend(test_labels.tolist())\n",
        "    \n",
        "    print('Classification Report:')\n",
        "    print(classification_report(y_true, y_pred, labels=[0,1,2,3,4,5,6], digits=4))\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4,5,6])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "\n",
        "    ax.xaxis.set_ticklabels(['0','1','2','3','4','5','6'])\n",
        "    ax.yaxis.set_ticklabels(['0','1','2','3','4','5','6'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "b6_cuv7Tp69E",
        "outputId": "810222d0-9dfb-404b-dbba-e1b58302a22e"
      },
      "source": [
        "best_model = BERT().to(device)\n",
        "load_checkpoint(os.path.join(ROOT_DIR, MODEL_DIR,'model.pt'), best_model)\n",
        "evaluate(best_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Cognizer/models/model.pt\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9814    0.9937    0.9875       159\n",
            "           1     1.0000    0.9828    0.9913       116\n",
            "           2     0.9512    0.9873    0.9689        79\n",
            "           3     0.9318    0.9111    0.9213        45\n",
            "           4     0.9000    0.9000    0.9000        40\n",
            "           5     1.0000    1.0000    1.0000        13\n",
            "           6     1.0000    0.7500    0.8571         8\n",
            "\n",
            "    accuracy                         0.9696       460\n",
            "   macro avg     0.9663    0.9321    0.9466       460\n",
            "weighted avg     0.9698    0.9696    0.9693       460\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD1O_nyl3oAf"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug4PCRsa5_ib",
        "outputId": "dab496f9-e3d2-4b67-bd09-d4eb1caa45a4"
      },
      "source": [
        "import time\n",
        "\n",
        "def infer(question):\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  encoding = tokenizer.encode_plus(\n",
        "      question,\n",
        "      add_special_tokens=True,\n",
        "      max_length=70,\n",
        "      return_token_type_ids=False,\n",
        "      # pad_to_max_length=True,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "  best_model = BERT().to('cpu')\n",
        "  load_checkpoint(os.path.join(ROOT_DIR, MODEL_DIR,'model.pt'), best_model)\n",
        "  start_time = time.time()\n",
        "  _, logits = best_model(encoding['input_ids'].to('cpu'), encoding['attention_mask'].to('cpu'), None)\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  print(label2tag(int(torch.argmax(logits).item())))\n",
        "  \n",
        "  \n",
        "infer(\"show me all e-mail address of Pallavi\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Cognizer/models/model.pt\n",
            "--- 0.18224883079528809 seconds ---\n",
            "Contact\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8bButc43l7Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kjzeBeLqIPo"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "best_model = BERT().to(device)\n",
        "load_checkpoint(os.path.join(ROOT_DIR, MODEL_DIR,'model.pt'), best_model)\n",
        "\n",
        "print(\"Predicted class - \", predict_class(\"show me all e-mail address of Pallavi\", infer(\"KNN\"))) #try with and without - in email\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymIen8ap9zvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}